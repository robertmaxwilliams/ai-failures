%%https://research.aimultiple.com/manufacturing-ai/
%%https://www.smartcitylab.com/blog/digital-transformation/singapore-experiments-with-its-digital-twin-to-improve-city-life/
%%https://www.3ds.com/customer-stories/single/virtual-singapore/
%\subsection{Digital Twin of Singapore}
%
%AI component to be analyzed: Crowd simulation
%
%Disparity between design and marketing: The digital twin was designed to be used to test changes to
%buildings and roads

%% Ugh it's way too big and nebulous for me to understand

Some ideas for kinds of failures:

Distribution Shift failure: When new situations or agents are added, a catastophe can occur to a
previously stable system

Interaction Failure: Agents with limited self awareness can cause catastrphes in the ways they
interact

Race to the Bottom: perverse insentives drive healthy competition into reward hacking territory and
forces prioritization of short term gains

Pollution of Distances: If your tech changes how people interact, it might damage social
institutions (democracy, capitalism, community cohesion, trust newtworks)

Reward Hacking type I: If you're optimizing something, it might optimize the reward correctly but in
a way that isn't useful

Reward hacking type II: If you're optimizing something, it might optimize for something other than
what you specified

Sandboxing failure: If you're sandboxing your AI, it might break out of the sandbox.

Off-label Usage: If you build a tool to do X with safety precautions a,b,c for that task, it might
be catastrophic if someone uses your tool for Y.






\cite{uesato2018adversarial}

20 pages, focused on rl training safe driverless card. Problem is that evaluating rl agaents
can take longer than training them, so add an adversary that evaluates them on the hard stuff,
like a driving instructor skipping straight to tight parallel parking when they see you're good

Doesn't actually list any failures

\cite{wallace2018landscapes}

33 pages. I like this already, taking the analogy of organizations as agents seriously.

This is a really complex paper, beyond me in a lot of ways but really neat.

\cite{anderson2005control}

20 pages. This is basically one big failure example, about a specific technique called ``adaptave
control". It also includes details about an overreaction to these failures, followed by ``don't use
it unless it's applicable" advice which has to be hammered into the naive buyers of COTS AI
software.

\cite{cook1998complex}

5 pages. \say{Post-accident attribution accident to a \say{root cause} is fundamentally wrong.}

Outch, okay yeah I get it. Damn.

\cite{carvin2017normal}

Uses \say{Charles Perrowâ€™s Normal Accident Theory} which might be of use to me since I'm doing
similar analysis but for all of society instead of just autonamous weapons.

\cite{maas2018regulating}
\cite{humbatova2019taxonomy}

\cite{virilio2007accident}

This was quite a read. The translation was very obtuse - things written in French are very hard to
understand. I'm not sure if the translators were simply trying to accumulate clout by being hard to
read, or if they were just trying their best to make it readable and weren't very successful. There
is a third option, that the original was so obtuse that translating any other way would be untrue to
the original. But I find that hard to believe. I think it's probably just a status move to make
French works hard to read.

I had to look up so many words, and a few still didn't quite make sense. This was very hard to read.

What is the Dromosphere? What \emph{really} is this \say{polution of distances} that Virilio speaks
of so frequently? He's comparing the Cold War era terror with internet connectivism. It doesn't seem
that drastic to have everyone online --- people still have smallish social spheres and even smaller
networks of trust. It is true that anyone I know can be contacted in moments. There are very few
geolocked social networks. 

The telescoping of all time all being slammed into one time and space... I don't know what that's
talking about. 

The accident museum is a cool idea. I think my paper (and those Yampolskiy has already written) are
a kind of accident museum, showcasing the failures of the past, regardless of safegaurds taken, or,
worse, to those so certain of what they were doing that they didn't think they needed any safeguards
at all.
